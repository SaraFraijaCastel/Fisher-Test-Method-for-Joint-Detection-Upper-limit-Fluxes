{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n",
      "/tmp/ipykernel_2362739/208895439.py:116: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data).T\n",
      "/tmp/ipykernel_2362739/208895439.py:116: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data).T\n",
      "/tmp/ipykernel_2362739/208895439.py:116: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data).T\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (3) does not match length of index (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 123\u001b[0m\n\u001b[1;32m    120\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSignificance\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEC\u001b[39m\u001b[38;5;124m'\u001b[39m,]\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, Data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns, data):\n\u001b[0;32m--> 123\u001b[0m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m Data\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#Agregar una columna para identificar el valor de psf\u001b[39;00m\n\u001b[1;32m    126\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSF\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m psf\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/site-packages/pandas/core/frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4090\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4091\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/site-packages/pandas/core/frame.py:4300\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4292\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4293\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4298\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4300\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4303\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4304\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4305\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4306\u001b[0m     ):\n\u001b[1;32m   4307\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/site-packages/pandas/core/frame.py:5039\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5039\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (3) does not match length of index (5)"
     ]
    }
   ],
   "source": [
    "# Author: Sara_Fraija\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Configuración de rutas\n",
    "GRBsINFO = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/GRBs_list.csv'\n",
    "PATH_GRBs_Healpix = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/healpix_maps/'\n",
    "PATH_GENERAL = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/'\n",
    "PATH_CODES = os.path.join(PATH_GENERAL, 'scripts')\n",
    "LABELS = ['1', '2']\n",
    "bin_size=0.25##PSF\n",
    "window_size=bin_size*2\n",
    "# Leer el archivo CSV\n",
    "GRBs = pd.read_csv(GRBsINFO)\n",
    "\n",
    "def generate_bash_script(grb, ra, dec, bin_size, path):\n",
    "    \"\"\"Genera un script Bash para un GRB específico.\"\"\"\n",
    "    PATH_GRBs = os.path.join(path, grb)\n",
    "    hist_path = os.path.join(PATH_GENERAL, 'SIG_ALL_GRBs')\n",
    "    os.makedirs(hist_path, exist_ok=True)\n",
    "    bin_size = max(bin_size, GRBs.loc[GRBs['Name'] == grb, 'Error_Radius'].values[0])\n",
    "\n",
    "    script = f\"\"\"#!/usr/bin/env bash\n",
    "#SBATCH --mem-per-cpu=4GB\n",
    "#SBATCH -o {PATH_GRBs}/{grb}/maps/codes/HIST.out\n",
    "#SBATCH --mail-type=all\n",
    "#SBATCH --mail-user=smfraijac@astro.unam.mx\n",
    "#SBATCH -J UL{grb}\n",
    "# Author: Sara_Fraija\n",
    "\n",
    "source /data/disk01/home/smfraijac/.bashrc\n",
    "hawc_aerie\n",
    "\n",
    "RA={ra}\n",
    "DEC={dec}\n",
    "Bin_size={bin_size}\n",
    "Hist_path={hist_path}\n",
    "Window_size={window_size}\n",
    "for Label in {LABELS[0]} {LABELS[1]}; do\n",
    "    GRB={grb}_$Label\n",
    "    output_file={hist_path}/{grb}_PSF_{bin_size}_Hist$Label.txt\n",
    "    max_output_file={PATH_GENERAL}/MaxSigHist_{bin_size}_$Label.txt\n",
    "    rm -f \"$output_file\"\n",
    "\n",
    "    transit_file={PATH_GRBs}/transit_$Label/{grb}_transit_$Label.fits.gz\n",
    "    # PL=$(makeSignificanceHistogram.py \"$transit_file\" --ra \"$RA\" --dec \"$DEC\" --includeArea --batch --binsize \"$Bin_size\" -o \"$Hist_path/$GRB.png\")\n",
    "    PL=$(plotMercator.py \"$transit_file\"  --magma --cross  --circle $RA $DEC $Bin_size --circleproperty white 2 1 --origin $RA $DEC $Window_size $Window_size -o \"$Hist_path/$GRB.png\")\n",
    "    echo -e \"$PL\" > \"$output_file\"\n",
    "\n",
    "    Maxi=$(grep \"Max\" \"$output_file\")\n",
    "    echo -e \"{grb},$Label,$Maxi\" >> \"$max_output_file\"\n",
    "done\n",
    "\"\"\"\n",
    "    return script\n",
    "\n",
    "def create_script_file(content, grb, bin_size):\n",
    "    \"\"\"Crea y guarda el script Bash en un archivo.\"\"\"\n",
    "    file_path = os.path.join(PATH_CODES, f'MaxSig{grb}_{bin_size}.sh')\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "def generate_scripts_for_all_grbs(bin_size, path):\n",
    "    \"\"\"Genera scripts para todos los GRBs en el archivo CSV.\"\"\"\n",
    "    for _, row in GRBs.iterrows():\n",
    "        grb, ra, dec = row['Name'], row['Ra'], row['Dec']\n",
    "        script_content = generate_bash_script(grb, ra, dec, bin_size, path)\n",
    "        create_script_file(script_content, grb, bin_size)\n",
    "\n",
    "def generate_batch_sender(bin_size):\n",
    "    \"\"\"Genera un script para ejecutar todos los scripts generados.\"\"\"\n",
    "    batch_file_path = os.path.join(PATH_CODES, f'BatchSenderMax_{bin_size}.sh')\n",
    "    os.makedirs(os.path.dirname(batch_file_path), exist_ok=True)\n",
    "    with open(batch_file_path, 'w') as batch_file:\n",
    "        batch_file.write(f'rm -f {PATH_GENERAL}/MaxSig_{bin_size}_*.txt\\n')\n",
    "        for grb in GRBs['Name']:\n",
    "            script_path = os.path.join(PATH_CODES, f'MaxSig{grb}_{bin_size}.sh')\n",
    "            batch_file.write(f'sh {script_path}\\n')\n",
    "\n",
    "# Generar scripts para bin_size = 0.6\n",
    "\n",
    "generate_scripts_for_all_grbs(bin_size, PATH_GRBs_Healpix)\n",
    "generate_batch_sender(bin_size)\n",
    "import subprocess\n",
    "subprocess.run([\"bash\",os.path.join(PATH_CODES, f'BatchSenderMax_{bin_size}.sh')])\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path='/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/GRBs_list.csv'\n",
    "coordi=pd.read_csv(path);\n",
    "# Lista para almacenar los DataFrames\n",
    "transit=1\n",
    "# Ruta del archivo y procesamiento\n",
    "for transit in [1,2]:\n",
    "    dfs = []    \n",
    "    for psf in [bin_size,0.70,0.8]:\n",
    "        path = f'../MaxSigHist_{psf}_{transit}.txt'\n",
    "        \n",
    "        # Leer el archivo de texto\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Procesar las líneas para extraer los datos\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            # Eliminar espacios en blanco al inicio y final de la línea\n",
    "            line = line = ' '.join(line.split())\n",
    "            line = line.replace('Max:', '').replace(')', '').replace('(', '').replace(' ', ',').replace(',,', ',')\n",
    "            # Reemplazar y dividir la línea\n",
    "            \n",
    "            line = line.split(',')\n",
    "            # print(line)\n",
    "            # Agregar a la lista de datos\n",
    "            data.append(line)\n",
    "        \n",
    "        # Convertir a un array de numpy y transponer\n",
    "        data = np.array(data).T\n",
    "        \n",
    "        # Crear un DataFrame\n",
    "        df = pd.DataFrame()\n",
    "        columns = ['Name','transit', 'Significance','RA', 'DEC',]\n",
    "        \n",
    "        for i, Data in zip(columns, data):\n",
    "            df[i] = Data\n",
    "        \n",
    "        #Agregar una columna para identificar el valor de psf\n",
    "        df['PSF'] = psf\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dfs.append(df)\n",
    "#!/usr/bin/env python3\n",
    "# AUTHOR: Sara Fraija\n",
    "# This script allows generating bash files to compute upper limits for each GRB. \n",
    "# You can change the GRB list, energy ranges, and EBL model.\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "# ------------------------------------------------------------------------\n",
    "# PATHS & FILENAMES\n",
    "# ------------------------------------------------------------------------\n",
    "energy_ranges = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/Energy_ranges.csv'\n",
    "GRBINFO_folder = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/'\n",
    "OUTPUT_folder = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/files/2.5/PSF_0.25/'\n",
    "os.makedirs(OUTPUT_folder,exist_ok=True)\n",
    "PATH_SH = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/codes/'\n",
    "RECALCULATED = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/corrected/'\n",
    "\n",
    "# Leer Energy_ranges.csv con nombres de columnas correctos\n",
    "Energy_ranges = pd.read_csv(energy_ranges, names=['Name', 'Emin', 'Emax'])\n",
    "Energy_ranges = Energy_ranges.set_index('Name')\n",
    "Energy_ranges.sort_values(by='Name')\n",
    "# ------------------------------------------------------------------------\n",
    "# Function to generate bash script\n",
    "# ------------------------------------------------------------------------\n",
    "def script(GRBINFO, transit, PATH_SH, OUTPUT_folder, RECALCULATED, EBL, PSF):\n",
    "    OUTPUT_FILE = f\"{OUTPUT_folder}UpperLimit_{transit}_{EBL}.csv\"\n",
    "\n",
    "    # Leer archivo CSV con GRB information\n",
    "    Data = pd.read_csv(GRBINFO)\n",
    "    Data.sort_values('Name')\n",
    "    # Verificar si la columna \"Name\" existe en el CSV\n",
    "    if \"Name\" not in Data.columns:\n",
    "        print(f\"Error: La columna 'Name' no está en {GRBINFO}. Verifica el formato del archivo.\")\n",
    "        print(f\"Columnas disponibles: {Data.columns}\")\n",
    "        return\n",
    "\n",
    "    # Usar \"Name\" como índice\n",
    "    Data = Data.set_index(\"Name\")\n",
    "\n",
    "    # Asignar valores de Emin y Emax si existen en Energy_ranges\n",
    "    Data['Emin'] = Data.index.map(Energy_ranges['Emin'])\n",
    "    Data['Emax'] = Data.index.map(Energy_ranges['Emax'])\n",
    "    # Verificar si hay valores NaN en Emin o Emax\n",
    "    if Data[['Emin', 'Emax']].isna().any().any():\n",
    "        print(\"Error: Algunos GRBs no tienen valores de Emin o Emax. Verifica Energy_ranges.csv.\")\n",
    "        print(Data[['Emin', 'Emax']].isna().sum())\n",
    "        return\n",
    "\n",
    "\n",
    "    line = \"\"\n",
    "    for grb in Data.index:  \n",
    "        row = Data.loc[grb]\n",
    "        RA = row['RA']\n",
    "        Dec = row['DEC']\n",
    "        z = row['z']\n",
    "        \n",
    "        index = 2.07 if grb == 'GRB170817529' else 2.5\n",
    "\n",
    "        Emin = row['Emin']\n",
    "        Emax = row['Emax']\n",
    "        line += f'PL=\"PowerLaw,1.0e-10,{index}\"\\n'\n",
    "        line_1=f\"ULs=$(zebra-flux-norm-fit -i $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB0C1_N1024.fits.gz $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB{{1..10}}C{{0..1}}_N1024.fits.gz -b B0C1 B{{1..10}}C{{0..1}} --extrapolate-low-z --dr $DR51 --ra {RA} --dec {Dec} -s $PL --ebl {EBL},{z} --pivot 1 --minE {Emin} --maxE {Emax} -V 3)\\n\"\n",
    "        line_2=f\"ULs=$(zebra-flux-norm-fit -i $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB{{0..10}}C{{0..1}}_N1024.fits.gz -b B{{0..10}}C{{0..1}} --extrapolate-low-z --dr $DR51 --ra {RA} --dec {Dec} -s $PL --ebl {EBL},{z} --pivot 1 --minE {Emin} --maxE {Emax} -V 3)\\n\"\n",
    "        line+=line_1 if grb=='GRB150110923'else line_2\n",
    "        line += f'echo -e \"{grb},${{ULs}}\" >> $output_file\\n'\n",
    "        \n",
    "\n",
    "    # Código base del script Bash\n",
    "    code = f\"\"\"#! /usr/bin/env bash\n",
    "#SBATCH --mem-per-cpu=4GB\n",
    "#SBATCH -o {PATH_SH}/logs/UL.out\n",
    "#SBATCH --mail-type=all\n",
    "#SBATCH --mail-user=smfraijac@astro.unam.mx\n",
    "#SBATCH -J UL\n",
    "# Author: Sara Fraija\n",
    "source /data/disk01/home/smfraijac/.bashrc\n",
    "hawc_aerie\n",
    "output_file={OUTPUT_FILE}\n",
    "DR51=/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/config/pass5.f_DR/zebra-100pct-FHit.root\n",
    "dir={RECALCULATED}\\n\n",
    "output_file={OUTPUT_FILE}\\n\n",
    "rm -f output_file\n",
    "\"\"\"\n",
    "    # Guardar el script Bash\n",
    "    file_path = f\"{PATH_SH}UL{transit}_{EBL}_{PSF}.sh\"\n",
    "    with open(file_path, 'w') as bash_file:\n",
    "        bash_file.write(code + line)\n",
    "    print(f\"Script generado: {file_path}\")\n",
    "# ------------------------------------------------------------------------\n",
    "# Running script\n",
    "# ------------------------------------------------------------------------\n",
    "EBL_list = ['Franceschini08', 'Gilmore12Fiducial']\n",
    "\n",
    "# for EBL in EBL_list:\n",
    "#     File_1st_transit = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/Coordinates_with_Max_Sig_1_00.25.csv'\n",
    "#     File_2nd_transit = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/Coordinates_with_Max_Sig_2_00.25.csv'\n",
    "#     script(File_1st_transit, transit=1, PATH_SH=PATH_SH, OUTPUT_folder=OUTPUT_folder, RECALCULATED=RECALCULATED, EBL=EBL, PSF=0.25)\n",
    "#     script(File_2nd_transit, transit=2, PATH_SH=PATH_SH, OUTPUT_folder=OUTPUT_folder, RECALCULATED=RECALCULATED, EBL=EBL, PSF=0.25)\n",
    "#     p1 = subprocess.Popen(['bash', f\"{PATH_SH}UL1_{EBL}_0.25.sh\"])\n",
    "#     p2 = subprocess.Popen(['bash', f\"{PATH_SH}UL2_{EBL}_0.25.sh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Ruta del archivo\n",
    "# path = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/MaxSigHist_0.6_1.txt'\n",
    "\n",
    "# # Leer el archivo de texto\n",
    "# with open(path, 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "\n",
    "# # Procesar las líneas para extraer los datos\n",
    "# data = []\n",
    "# for line in lines:\n",
    "#     # Eliminar espacios en blanco al inicio y final de la línea\n",
    "#     line = line.strip()\n",
    "#     print(line)\n",
    "    \n",
    "#     # Verificar si la línea tiene el formato esperado\n",
    "#     if not line:\n",
    "#         continue  # Saltar líneas vacías\n",
    "    \n",
    "#     try:\n",
    "#         # Dividir la línea en partes usando la coma como separador\n",
    "#         parts = line.split(',')\n",
    "#         if len(parts) < 3:\n",
    "#             print(f\"Línea ignorada (formato incorrecto): {line}\")\n",
    "#             continue\n",
    "        \n",
    "#         grb_id = parts[0]\n",
    "        \n",
    "#         # Extraer las coordenadas y la significancia\n",
    "#         coords_part = parts[2].split('(')\n",
    "#         if len(coords_part) < 2:\n",
    "#             print(f\"Línea ignorada (formato de coordenadas incorrecto): {line}\")\n",
    "#             continue\n",
    "        \n",
    "#         coords_part = coords_part[1].split(')')[0]  # Extraer \"(RA, Dec)\"\n",
    "#         coords = coords_part.split(',')  # Dividir en RA y Dec\n",
    "        \n",
    "#         if len(coords) < 2:\n",
    "#             print(f\"Línea ignorada (coordenadas incompletas): {line}\")\n",
    "#             continue\n",
    "        \n",
    "#         # Eliminar espacios en blanco y convertir a float\n",
    "#         ra = float(coords[0].strip())\n",
    "#         dec = float(coords[1].strip())\n",
    "        \n",
    "#         # Extraer la significancia\n",
    "#         significance_part = parts[2].split('is ')\n",
    "#         if len(significance_part) < 2:\n",
    "#             print(f\"Línea ignorada (formato de significancia incorrecto): {line}\")\n",
    "#             continue\n",
    "        \n",
    "#         significance = float(significance_part[1].strip())  # Convertir a float\n",
    "        \n",
    "#         # Agregar los datos a la lista\n",
    "#         data.append([grb_id, ra, dec, significance])\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error procesando la línea: {line}\")\n",
    "#         print(f\"Detalles del error: {e}\")\n",
    "#         continue\n",
    "\n",
    "# # Crear un DataFrame con los datos\n",
    "# df = pd.DataFrame(data, columns=['GRB ID', 'RA_max', 'Dec_max', 'Significance'])\n",
    "\n",
    "# # Mostrar la tabla\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name transit Significance      RA     DEC   PSF       Ra  \\\n",
      "0    GRB150110923       1         1.10  289.64   32.71  0.25  289.360   \n",
      "1    GRB150922234       1         2.15  294.43   -5.27  0.25  294.381   \n",
      "2    GRB160726065       1         1.24   98.96   -6.92  0.25   98.821   \n",
      "3    GRB170325331       1         1.03  127.27   20.78  0.25  127.483   \n",
      "4    GRB180715755       1         0.93  235.28   -1.16  0.25  235.069   \n",
      "5    GRB180718082       1         1.29  336.31    2.69  0.25  336.019   \n",
      "6    GRB181125371       1         0.74  268.55   -2.54  0.25  268.413   \n",
      "7    GRB190427190       1         1.85  279.98   40.13  0.25  280.213   \n",
      "8    GRB201008443       1         1.70  162.10   45.83  0.25  161.859   \n",
      "9    GRB201221963       1         0.00  170.80   42.41  0.25  171.059   \n",
      "10   GRB210323918       1         1.56  317.72   25.65  0.25  317.946   \n",
      "11   GRB170817529       1         2.53  197.67  -23.44  0.25  197.500   \n",
      "66   GRB160726065       1         1.21   98.96   -6.92  0.25   98.821   \n",
      "67   GRB170325331       1         1.22  127.27   20.78  0.25  127.483   \n",
      "69   GRB180718082       1         1.26  336.31    2.69  0.25  336.019   \n",
      "70   GRB181125371       1         0.73  268.55   -2.54  0.25  268.413   \n",
      "71   GRB190427190       1         1.77  279.98   40.13  0.25  280.213   \n",
      "162  GRB170403583       1         0.29  259.54   18.09  0.70  259.339   \n",
      "167  GRB170403583       1         1.62  258.88   17.74  0.70  259.339   \n",
      "172  GRB170403583       1         0.38  259.54   18.09  0.70  259.339   \n",
      "180  GRB170222209       1         1.51  292.76   28.16  0.80  292.956   \n",
      "185  GRB170222209       1         1.81  292.41   27.91  0.80  292.956   \n",
      "190  GRB170222209       1         1.57  292.76   28.16  0.80  292.956   \n",
      "\n",
      "         Dec  Tstart (GPS)  Tstop (GPS)  GPS time in HAWCFoV     Tstart  \\\n",
      "0    32.5220    1105025552   1105046072           1104962912  17.399963   \n",
      "1    -5.4860    1126999829   1127017949           1126935449  17.883230   \n",
      "2    -6.6440    1153577948   1153595588           1153532048  12.750069   \n",
      "3    20.5260    1174520758   1174542238           1174463818  15.816731   \n",
      "4    -0.9250    1215734045   1215753365           1215713225   5.783341   \n",
      "5     2.7900    1215930165   1215950205           1215914265   4.416758   \n",
      "6    -2.6130    1227202062   1227220902           1227171282   8.550088   \n",
      "7    40.3220    1240387935   1240406895           1240374855   3.633278   \n",
      "8    46.1019    1286199817   1286216977           1286188657   3.100097   \n",
      "9    42.1432    1292663675   1292663675           1292682155   0.000000   \n",
      "10   25.3699    1300624519   1300645759           1300572138  14.550037   \n",
      "11  -23.4000    1187038412   1187045718                    0   0.000000   \n",
      "66   -6.6440    1153577948   1153595588           1153532048  12.750069   \n",
      "67   20.5260    1174520758   1174542238           1174463818  15.816731   \n",
      "69    2.7900    1215930165   1215950205           1215914265   4.416758   \n",
      "70   -2.6130    1227202062   1227220902           1227171282   8.550088   \n",
      "71   40.3220    1240387935   1240406895           1240374855   3.633278   \n",
      "162  18.3730    1175327777   1175349257           1175263158  17.949883   \n",
      "167  18.3730    1175327777   1175349257           1175263158  17.949883   \n",
      "172  18.3730    1175327777   1175349257           1175263158  17.949883   \n",
      "180  28.2110    1171803359   1171824359           1171774859   7.916735   \n",
      "185  28.2110    1171803359   1171824359           1171774859   7.916735   \n",
      "190  28.2110    1171803359   1171824359           1171774859   7.916735   \n",
      "\n",
      "         Tstop      z  Error_Radius  \n",
      "0    23.099963  0.009        0.0500  \n",
      "1    22.916563  0.009        0.1800  \n",
      "2    17.650069  0.009        0.0500  \n",
      "3    21.783397  0.009        0.0300  \n",
      "4    11.150007  0.009        0.0500  \n",
      "5     9.983424  0.009        0.0500  \n",
      "6    13.783421  0.009        0.0500  \n",
      "7     8.899944  0.009        0.0500  \n",
      "8     7.866764  0.009        0.0013  \n",
      "9     0.000000  0.009        0.0010  \n",
      "10   20.450037  0.009        0.0050  \n",
      "11    8.300000  0.009        0.0000  \n",
      "66   17.650069  0.009        0.0500  \n",
      "67   21.783397  0.009        0.0300  \n",
      "69    9.983424  0.009        0.0500  \n",
      "70   13.783421  0.009        0.0500  \n",
      "71    8.899944  0.009        0.0500  \n",
      "162  23.916550  0.009        0.7000  \n",
      "167  23.916550  0.009        0.7000  \n",
      "172  23.916550  0.009        0.7000  \n",
      "180  13.750069  0.009        0.8000  \n",
      "185  13.750069  0.009        0.8000  \n",
      "190  13.750069  0.009        0.8000  \n",
      "            Name       transit  Significance            RA           DEC  \\\n",
      "0   GRB150110923  GRB150922234  GRB160726065  GRB170325331  GRB180715755   \n",
      "1              2             2             2             2             2   \n",
      "2           1.83          1.65          0.25          1.65          0.46   \n",
      "3         289.07        294.52         98.53        127.22        235.06   \n",
      "4          32.49         -5.27         -6.39         20.34         -1.12   \n",
      "5   GRB170403583             2          1.29        259.28         18.09   \n",
      "10  GRB170403583             2          2.60        259.98         18.96   \n",
      "23  GRB170222209             2          1.60        292.68         28.00   \n",
      "28  GRB170222209             2          2.20        292.50         27.91   \n",
      "\n",
      "     PSF       Ra     Dec  Tstart (GPS)   Tstop (GPS)  GPS time in HAWCFoV  \\\n",
      "0   0.25  289.360  32.522  1.105026e+09  1.105046e+09         1.104963e+09   \n",
      "1   0.25      NaN     NaN           NaN           NaN                  NaN   \n",
      "2   0.25      NaN     NaN           NaN           NaN                  NaN   \n",
      "3   0.25      NaN     NaN           NaN           NaN                  NaN   \n",
      "4   0.25      NaN     NaN           NaN           NaN                  NaN   \n",
      "5   0.70  259.339  18.373  1.175328e+09  1.175349e+09         1.175263e+09   \n",
      "10  0.70  259.339  18.373  1.175328e+09  1.175349e+09         1.175263e+09   \n",
      "23  0.80  292.956  28.211  1.171803e+09  1.171824e+09         1.171775e+09   \n",
      "28  0.80  292.956  28.211  1.171803e+09  1.171824e+09         1.171775e+09   \n",
      "\n",
      "       Tstart      Tstop      z  Error_Radius  \n",
      "0   17.399963  23.099963  0.009          0.05  \n",
      "1         NaN        NaN    NaN           NaN  \n",
      "2         NaN        NaN    NaN           NaN  \n",
      "3         NaN        NaN    NaN           NaN  \n",
      "4         NaN        NaN    NaN           NaN  \n",
      "5   17.949883  23.916550  0.009          0.70  \n",
      "10  17.949883  23.916550  0.009          0.70  \n",
      "23   7.916735  13.750069  0.009          0.80  \n",
      "28   7.916735  13.750069  0.009          0.80  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2168043/3541833435.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data).T\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path='/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/GRBs_list.csv'\n",
    "coordi=pd.read_csv(path);\n",
    "# Lista para almacenar los DataFrames\n",
    "transit=1\n",
    "# Ruta del archivo y procesamiento\n",
    "for transit in [1,2]:\n",
    "    dfs = []    \n",
    "    for psf in [bin_size,0.7,0.8]:\n",
    "        path = f'../MaxSigHist_{psf}_{transit}.txt'\n",
    "        \n",
    "        # Leer el archivo de texto\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Procesar las líneas para extraer los datos\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            # Eliminar espacios en blanco al inicio y final de la línea\n",
    "            line = line = ' '.join(line.split())\n",
    "            line = line.replace('Max:', '').replace(')', '').replace('(', '').replace(' ', ',').replace(',,', ',')\n",
    "            # Reemplazar y dividir la línea\n",
    "            \n",
    "            line = line.split(',')\n",
    "            # print(line)\n",
    "            # Agregar a la lista de datos\n",
    "            data.append(line)\n",
    "        \n",
    "        # Convertir a un array de numpy y transponer\n",
    "        data = np.array(data).T\n",
    "        \n",
    "        # Crear un DataFrame\n",
    "        df = pd.DataFrame()\n",
    "        columns = ['Name','transit', 'Significance','RA', 'DEC',]\n",
    "        \n",
    "        for i, Data in zip(columns, data):\n",
    "            df[i] = Data\n",
    "        \n",
    "        #Agregar una columna para identificar el valor de psf\n",
    "        df['PSF'] = psf\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Combinar todos los DataFrames en uno solo\n",
    "    combined_df = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "    C=combined_df.join(coordi.set_index('Name'),on='Name')\n",
    "    C.to_csv(f'../config/Coordinates_with_Max_Sig_{transit}_0{bin_size}.csv')\n",
    "    # Mostrar el DataFrame combinado\n",
    "    print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['bash', '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/scripts/BatchSenderMax_0.25.sh'], returncode=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Sara_Fraija\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Configuración de rutas\n",
    "GRBsINFO = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/GRBs_list.csv'\n",
    "PATH_GRBs_Healpix = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/healpix_maps/'\n",
    "PATH_GENERAL = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/'\n",
    "PATH_CODES = os.path.join(PATH_GENERAL, 'scripts')\n",
    "LABELS = ['1', '2']\n",
    "bin_size=0.25##PSF\n",
    "window_size=bin_size*2\n",
    "# Leer el archivo CSV\n",
    "GRBs = pd.read_csv(GRBsINFO)\n",
    "\n",
    "def generate_bash_script(grb, ra, dec, bin_size, path):\n",
    "    \"\"\"Genera un script Bash para un GRB específico.\"\"\"\n",
    "    PATH_GRBs = os.path.join(path, grb)\n",
    "    hist_path = os.path.join(PATH_GENERAL, 'SIG_ALL_GRBs')\n",
    "    os.makedirs(hist_path, exist_ok=True)\n",
    "    bin_size = max(bin_size, GRBs.loc[GRBs['Name'] == grb, 'Error_Radius'].values[0])\n",
    "\n",
    "    script = f\"\"\"#!/usr/bin/env bash\n",
    "#SBATCH --mem-per-cpu=4GB\n",
    "#SBATCH -o {PATH_GRBs}/{grb}/maps/codes/HIST.out\n",
    "#SBATCH --mail-type=all\n",
    "#SBATCH --mail-user=smfraijac@astro.unam.mx\n",
    "#SBATCH -J UL{grb}\n",
    "# Author: Sara_Fraija\n",
    "\n",
    "source /data/disk01/home/smfraijac/.bashrc\n",
    "hawc_aerie\n",
    "\n",
    "RA={ra}\n",
    "DEC={dec}\n",
    "Bin_size={bin_size}\n",
    "Hist_path={hist_path}\n",
    "Window_size={window_size}\n",
    "for Label in {LABELS[0]} {LABELS[1]}; do\n",
    "    GRB={grb}_$Label\n",
    "    output_file={hist_path}/{grb}_PSF_{bin_size}_Hist$Label.txt\n",
    "    max_output_file={PATH_GENERAL}/MaxSigHist_{bin_size}_$Label.txt\n",
    "    rm -f \"$output_file\"\n",
    "\n",
    "    transit_file={PATH_GRBs}/transit_$Label/{grb}_transit_$Label.fits.gz\n",
    "    # PL=$(makeSignificanceHistogram.py \"$transit_file\" --ra \"$RA\" --dec \"$DEC\" --includeArea --batch --binsize \"$Bin_size\" -o \"$Hist_path/$GRB.png\")\n",
    "    PL=$(plotMercator.py \"$transit_file\"  --magma --cross  --circle $RA $DEC $Bin_size --circleproperty white 2 1 --origin $RA $DEC $Window_size $Window_size -o \"$Hist_path/$GRB.png\")\n",
    "    echo -e \"$PL\" > \"$output_file\"\n",
    "\n",
    "    Maxi=$(grep \"Max\" \"$output_file\")\n",
    "    echo -e \"{grb},$Label,$Maxi\" >> \"$max_output_file\"\n",
    "done\n",
    "\"\"\"\n",
    "    return script\n",
    "\n",
    "def create_script_file(content, grb, bin_size):\n",
    "    \"\"\"Crea y guarda el script Bash en un archivo.\"\"\"\n",
    "    file_path = os.path.join(PATH_CODES, f'MaxSig{grb}_{bin_size}.sh')\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "def generate_scripts_for_all_grbs(bin_size, path):\n",
    "    \"\"\"Genera scripts para todos los GRBs en el archivo CSV.\"\"\"\n",
    "    for _, row in GRBs.iterrows():\n",
    "        grb, ra, dec = row['Name'], row['Ra'], row['Dec']\n",
    "        script_content = generate_bash_script(grb, ra, dec, bin_size, path)\n",
    "        create_script_file(script_content, grb, bin_size)\n",
    "\n",
    "def generate_batch_sender(bin_size):\n",
    "    \"\"\"Genera un script para ejecutar todos los scripts generados.\"\"\"\n",
    "    batch_file_path = os.path.join(PATH_CODES, f'BatchSenderMax_{bin_size}.sh')\n",
    "    os.makedirs(os.path.dirname(batch_file_path), exist_ok=True)\n",
    "    with open(batch_file_path, 'w') as batch_file:\n",
    "        batch_file.write(f'rm -f {PATH_GENERAL}/MaxSig_{bin_size}_*.txt\\n')\n",
    "        for grb in GRBs['Name']:\n",
    "            script_path = os.path.join(PATH_CODES, f'MaxSig{grb}_{bin_size}.sh')\n",
    "            batch_file.write(f'sh {script_path}\\n')\n",
    "\n",
    "# Generar scripts para bin_size = 0.6\n",
    "\n",
    "generate_scripts_for_all_grbs(bin_size, PATH_GRBs_Healpix)\n",
    "generate_batch_sender(bin_size)\n",
    "import subprocess\n",
    "subprocess.run([\"bash\",os.path.join(PATH_CODES, f'BatchSenderMax_{bin_size}.sh')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2168043/4250212157.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mEBL\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEBL_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mFile_1st_transit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/MaxSigHist_0.25_1.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mFile_2nd_transit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/MaxSigHist_0.25_2.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFile_1st_transit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH_SH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_SH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECALCULATED\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRECALCULATED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEBL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEBL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFile_2nd_transit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH_SH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_SH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRECALCULATED\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRECALCULATED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEBL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEBL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{PATH_SH}UL1_{EBL}_0.25.sh\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{PATH_SH}UL2_{EBL}_0.25.sh\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2168043/4250212157.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(GRBINFO, transit, PATH_SH, OUTPUT_folder, RECALCULATED, EBL, PSF)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mOUTPUT_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{OUTPUT_folder}UpperLimit_{transit}_{EBL}.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Leer archivo CSV con GRB information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRBINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Verificar si la columna \"Name\" existe en el CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Name\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: La columna 'Name' no está en {GRBINFO}. Verifica el formato del archivo.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6940\u001b[0m             )\n\u001b[1;32m   6941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6942\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6944\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6946\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6947\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "path='/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/GRBs_list.csv'\n",
    "coordi=pd.read_csv(path);\n",
    "# Lista para almacenar los DataFrames\n",
    "transit=1\n",
    "# Ruta del archivo y procesamiento\n",
    "for transit in [1,2]:\n",
    "    dfs = []    \n",
    "    for psf in [bin_size,0.70,0.8]:\n",
    "        path = f'../MaxSigHist_{psf}_{transit}.txt'\n",
    "        \n",
    "        # Leer el archivo de texto\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Procesar las líneas para extraer los datos\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            # Eliminar espacios en blanco al inicio y final de la línea\n",
    "            line = line = ' '.join(line.split())\n",
    "            line = line.replace('Max:', '').replace(')', '').replace('(', '').replace(' ', ',').replace(',,', ',')\n",
    "            # Reemplazar y dividir la línea\n",
    "            \n",
    "            line = line.split(',')\n",
    "            # print(line)\n",
    "            # Agregar a la lista de datos\n",
    "            data.append(line)\n",
    "        \n",
    "        # Convertir a un array de numpy y transponer\n",
    "        data = np.array(data).T\n",
    "        \n",
    "        # Crear un DataFrame\n",
    "        df = pd.DataFrame()\n",
    "        columns = ['Name','transit', 'Significance','RA', 'DEC',]\n",
    "        \n",
    "        for i, Data in zip(columns, data):\n",
    "            df[i] = Data\n",
    "        \n",
    "        #Agregar una columna para identificar el valor de psf\n",
    "        df['PSF'] = psf\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dfs.append(df)\n",
    "#!/usr/bin/env python3\n",
    "# AUTHOR: Sara Fraija\n",
    "# This script allows generating bash files to compute upper limits for each GRB. \n",
    "# You can change the GRB list, energy ranges, and EBL model.\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "# ------------------------------------------------------------------------\n",
    "# PATHS & FILENAMES\n",
    "# ------------------------------------------------------------------------\n",
    "energy_ranges = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/Energy_ranges.csv'\n",
    "GRBINFO_folder = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/'\n",
    "OUTPUT_folder = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/files/2.5/PSF_0.25/'\n",
    "os.makedirs(OUTPUT_folder,exist_ok=True)\n",
    "PATH_SH = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/codes/'\n",
    "RECALCULATED = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/corrected/'\n",
    "\n",
    "# Leer Energy_ranges.csv con nombres de columnas correctos\n",
    "Energy_ranges = pd.read_csv(energy_ranges, names=['Name', 'Emin', 'Emax'])\n",
    "Energy_ranges = Energy_ranges.set_index('Name')\n",
    "Energy_ranges.sort_values(by='Name')\n",
    "# ------------------------------------------------------------------------\n",
    "# Function to generate bash script\n",
    "# ------------------------------------------------------------------------\n",
    "def script(GRBINFO, transit, PATH_SH, OUTPUT_folder, RECALCULATED, EBL, PSF):\n",
    "    OUTPUT_FILE = f\"{OUTPUT_folder}UpperLimit_{transit}_{EBL}.csv\"\n",
    "\n",
    "    # Leer archivo CSV con GRB information\n",
    "    Data = pd.read_csv(GRBINFO)\n",
    "    Data.sort_values('Name')\n",
    "    # Verificar si la columna \"Name\" existe en el CSV\n",
    "    if \"Name\" not in Data.columns:\n",
    "        print(f\"Error: La columna 'Name' no está en {GRBINFO}. Verifica el formato del archivo.\")\n",
    "        print(f\"Columnas disponibles: {Data.columns}\")\n",
    "        return\n",
    "\n",
    "    # Usar \"Name\" como índice\n",
    "    Data = Data.set_index(\"Name\")\n",
    "\n",
    "    # Asignar valores de Emin y Emax si existen en Energy_ranges\n",
    "    Data['Emin'] = Data.index.map(Energy_ranges['Emin'])\n",
    "    Data['Emax'] = Data.index.map(Energy_ranges['Emax'])\n",
    "    # Verificar si hay valores NaN en Emin o Emax\n",
    "    if Data[['Emin', 'Emax']].isna().any().any():\n",
    "        print(\"Error: Algunos GRBs no tienen valores de Emin o Emax. Verifica Energy_ranges.csv.\")\n",
    "        print(Data[['Emin', 'Emax']].isna().sum())\n",
    "        return\n",
    "\n",
    "\n",
    "    line = \"\"\n",
    "    for grb in Data.index:  \n",
    "        row = Data.loc[grb]\n",
    "        RA = row['RA']\n",
    "        Dec = row['DEC']\n",
    "        z = row['z']\n",
    "        \n",
    "        index = 2.07 if grb == 'GRB170817529' else 2.5\n",
    "\n",
    "        Emin = row['Emin']\n",
    "        Emax = row['Emax']\n",
    "        line += f'PL=\"PowerLaw,1.0e-10,{index}\"\\n'\n",
    "        line_1=f\"ULs=$(zebra-flux-norm-fit -i $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB0C1_N1024.fits.gz $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB{{1..10}}C{{0..1}}_N1024.fits.gz -b B0C1 B{{1..10}}C{{0..1}} --extrapolate-low-z --dr $DR51 --ra {RA} --dec {Dec} -s $PL --ebl {EBL},{z} --pivot 1 --minE {Emin} --maxE {Emax} -V 3)\\n\"\n",
    "        line_2=f\"ULs=$(zebra-flux-norm-fit -i $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB{{0..10}}C{{0..1}}_N1024.fits.gz -b B{{0..10}}C{{0..1}} --extrapolate-low-z --dr $DR51 --ra {RA} --dec {Dec} -s $PL --ebl {EBL},{z} --pivot 1 --minE {Emin} --maxE {Emax} -V 3)\\n\"\n",
    "        line+=line_1 if grb=='GRB150110923'else line_2\n",
    "        line += f'echo -e \"{grb},${{ULs}}\" >> $output_file\\n'\n",
    "        \n",
    "\n",
    "    # Código base del script Bash\n",
    "    code = f\"\"\"#! /usr/bin/env bash\n",
    "#SBATCH --mem-per-cpu=4GB\n",
    "#SBATCH -o {PATH_SH}/logs/UL.out\n",
    "#SBATCH --mail-type=all\n",
    "#SBATCH --mail-user=smfraijac@astro.unam.mx\n",
    "#SBATCH -J UL\n",
    "# Author: Sara Fraija\n",
    "source /data/disk01/home/smfraijac/.bashrc\n",
    "hawc_aerie\n",
    "output_file={OUTPUT_FILE}\n",
    "DR51=/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/config/pass5.f_DR/zebra-100pct-FHit.root\n",
    "dir={RECALCULATED}\\n\n",
    "output_file={OUTPUT_FILE}\\n\n",
    "\"\"\"\n",
    "    # Guardar el script Bash\n",
    "    file_path = f\"{PATH_SH}UL{transit}_{EBL}_{PSF}.sh\"\n",
    "    with open(file_path, 'w') as bash_file:\n",
    "        bash_file.write(code + line)\n",
    "    print(f\"Script generado: {file_path}\")\n",
    "# ------------------------------------------------------------------------\n",
    "# Running script\n",
    "# ------------------------------------------------------------------------\n",
    "EBL_list = ['Franceschini08', 'Gilmore12Fiducial']\n",
    "\n",
    "for EBL in EBL_list:\n",
    "    File_1st_transit = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/MaxSigHist_0.25_1.txt'\n",
    "    File_2nd_transit = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/MaxSigHist_0.25_2.txt'\n",
    "    script(File_1st_transit, transit=1, PATH_SH=PATH_SH, OUTPUT_folder=OUTPUT_folder, RECALCULATED=RECALCULATED, EBL=EBL, PSF=0.25)\n",
    "    script(File_2nd_transit, transit=2, PATH_SH=PATH_SH, OUTPUT_folder=OUTPUT_folder, RECALCULATED=RECALCULATED, EBL=EBL, PSF=0.25)\n",
    "    p1 = subprocess.Popen(['bash', f\"{PATH_SH}UL1_{EBL}_0.25.sh\"])\n",
    "    p2 = subprocess.Popen(['bash', f\"{PATH_SH}UL2_{EBL}_0.25.sh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['bash', '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/scripts/BatchSenderMax_0.25.sh'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Sara_Fraija\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Configuración de rutas\n",
    "GRBsINFO = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/GRBs_list.csv'\n",
    "PATH_GRBs_Healpix = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/healpix_maps/'\n",
    "PATH_GENERAL = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/'\n",
    "PATH_CODES = os.path.join(PATH_GENERAL, 'scripts')\n",
    "LABELS = ['1', '2']\n",
    "bin_size = 0.25  ##PSF\n",
    "window_size = bin_size * 2\n",
    "# Leer el archivo CSV\n",
    "GRBs = pd.read_csv(GRBsINFO)\n",
    "for i in []\n",
    "def generate_bash_script(grb, ra, dec, bin_size, path):\n",
    "    \"\"\"Genera un script Bash para un GRB específico.\"\"\"\n",
    "    PATH_GRBs = os.path.join(path, grb)\n",
    "    hist_path = os.path.join(PATH_GENERAL, 'SIG_ALL_GRBs')\n",
    "    os.makedirs(hist_path, exist_ok=True)\n",
    "    bin_size = max(bin_size, GRBs.loc[GRBs['Name'] == grb, 'Error_Radius'].values[0])\n",
    "\n",
    "    script = f\"\"\"#!/usr/bin/env bash\n",
    "#SBATCH --mem-per-cpu=4GB\n",
    "#SBATCH -o {PATH_GRBs}/{grb}/maps/codes/HIST.out\n",
    "#SBATCH --mail-type=all\n",
    "#SBATCH --mail-user=smfraijac@astro.unam.mx\n",
    "#SBATCH -J UL{grb}\n",
    "# Author: Sara_Fraija\n",
    "\n",
    "source /data/disk01/home/smfraijac/.bashrc\n",
    "hawc_aerie\n",
    "\n",
    "RA={ra}\n",
    "DEC={dec}\n",
    "Bin_size={bin_size}\n",
    "Hist_path={hist_path}\n",
    "Window_size={window_size}\n",
    "for Label in {LABELS[0]} {LABELS[1]}; do\n",
    "    GRB={grb}_$Label\n",
    "    output_file={hist_path}/{grb}_PSF_{bin_size}_Hist$Label.txt\n",
    "    max_output_file={PATH_GENERAL}/MaxSigHist_{bin_size}_$Label.txt\n",
    "    rm -f \"$output_file\"\n",
    "\n",
    "    transit_file={PATH_GRBs}/transit_$Label/{grb}_transit_$Label.fits.gz\n",
    "    # PL=$(makeSignificanceHistogram.py \"$transit_file\" --ra \"$RA\" --dec \"$DEC\" --includeArea --batch --binsize \"$Bin_size\" -o \"$Hist_path/$GRB.png\")\n",
    "    PL=$(plotMercator.py \"$transit_file\"  --magma --cross  --circle $RA $DEC $Bin_size --circleproperty white 2 1 --origin $RA $DEC $Window_size $Window_size -o \"$Hist_path/$GRB.png\")\n",
    "    echo -e \"$PL\" > \"$output_file\"\n",
    "\n",
    "    Maxi=$(grep \"Max\" \"$output_file\")\n",
    "    echo -e \"{grb},$Label,$Maxi\" >> \"$max_output_file\"\n",
    "done\n",
    "\"\"\"\n",
    "    return script\n",
    "\n",
    "def create_script_file(content, grb, bin_size):\n",
    "    \"\"\"Crea y guarda el script Bash en un archivo.\"\"\"\n",
    "    file_path = os.path.join(PATH_CODES, f'MaxSig{grb}_{bin_size}.sh')\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "def generate_scripts_for_all_grbs(bin_size, path):\n",
    "    \"\"\"Genera scripts para todos los GRBs en el archivo CSV.\"\"\"\n",
    "    for _, row in GRBs.iterrows():\n",
    "        grb, ra, dec = row['Name'], row['Ra'], row['Dec']\n",
    "        script_content = generate_bash_script(grb, ra, dec, bin_size, path)\n",
    "        create_script_file(script_content, grb, bin_size)\n",
    "\n",
    "def generate_batch_sender(bin_size):\n",
    "    \"\"\"Genera un script para ejecutar todos los scripts generados.\"\"\"\n",
    "    batch_file_path = os.path.join(PATH_CODES, f'BatchSenderMax_{bin_size}.sh')\n",
    "    os.makedirs(os.path.dirname(batch_file_path), exist_ok=True)\n",
    "    if os.path.exists(batch_file_path):\n",
    "        os.remove(batch_file_path)\n",
    "    with open(batch_file_path, 'w') as batch_file:\n",
    "        batch_file.write(f'rm -f {PATH_GENERAL}/MaxSig_{bin_size}_*.txt\\n')\n",
    "        for grb in GRBs['Name']:\n",
    "            script_path = os.path.join(PATH_CODES, f'MaxSig{grb}_{bin_size}.sh')\n",
    "            batch_file.write(f'sh {script_path}\\n')\n",
    "\n",
    "# Generar scripts para bin_size = 0.6\n",
    "\n",
    "generate_scripts_for_all_grbs(bin_size, PATH_GRBs_Healpix)\n",
    "generate_batch_sender(bin_size)\n",
    "import subprocess\n",
    "subprocess.run([\"bash\", os.path.join(PATH_CODES, f'BatchSenderMax_{bin_size}.sh')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activate HAWC enviroment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Configuration file found, will be ignored in favour of command line\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/disk01/home/smfraijac/hawc_software/hawc_aerie/aerie/install/bin/plotMercator.py\", line 1114, in <module>\n",
      "    main()\n",
      "  File \"/data/disk01/home/smfraijac/hawc_software/hawc_aerie/aerie/install/bin/plotMercator.py\", line 642, in main\n",
      "    return_projected_map=True)\n",
      "  File \"/data/disk01/home/smfraijac/hawc_software/miniconda3/envs/aerie_env/lib/python2.7/site-packages/healpy/visufunc.py\", line 526, in cartview\n",
      "    map = pixelfunc.ma_to_array(map)\n",
      "  File \"/data/disk01/home/smfraijac/hawc_software/miniconda3/envs/aerie_env/lib/python2.7/site-packages/healpy/pixelfunc.py\", line 233, in ma_to_array\n",
      "    return m.filled()\n",
      "  File \"/data/disk01/home/smfraijac/hawc_software/miniconda3/envs/aerie_env/lib/python2.7/site-packages/numpy/ma/core.py\", line 3724, in filled\n",
      "    np.copyto(result, fill_value, where=m)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_CODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBatchSenderMax_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbin_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/subprocess.py:1201\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/subprocess.py:1264\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/subprocess.py:2046\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2045\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 2046\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/hawc_software/miniconda3/envs/3ML/lib/python3.11/subprocess.py:2004\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2004\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mwaitpid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid, wait_flags)\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   2007\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   2008\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   2009\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/GRBs_list.csv'\n",
    "coordi = pd.read_csv(path)\n",
    "# Lista para almacenar los DataFrames\n",
    "transit = 1\n",
    "# Ruta del archivo y procesamiento\n",
    "for transit in [1, 2]:\n",
    "    dfs = []    \n",
    "    for psf in [bin_size, 0.70, 0.8]:\n",
    "        path = f'../MaxSigHist_{psf}_{transit}.txt'\n",
    "        # Leer el archivo de texto\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Procesar las líneas para extraer los datos\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            # Eliminar espacios en blanco al inicio y final de la línea\n",
    "            line = ' '.join(line.split())\n",
    "            line = line.replace('Max:', '').replace(')', '').replace('(', '').replace(' ', ',').replace(',,', ',')\n",
    "            # Reemplazar y dividir la línea\n",
    "            line = line.split(',')\n",
    "            # Agregar a la lista de datos\n",
    "            data.append(line)\n",
    "        \n",
    "        # Convertir a un array de numpy y transponer\n",
    "        data = np.array(data).T\n",
    "        \n",
    "        # Crear un DataFrame\n",
    "        df = pd.DataFrame()\n",
    "        columns = ['Name', 'transit', 'Significance', 'RA', 'DEC']\n",
    "        \n",
    "        for i, Data in zip(columns, data):\n",
    "            df[i] = Data\n",
    "        \n",
    "        # Agregar una columna para identificar el valor de psf\n",
    "        df['PSF'] = psf\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dfs.append(df)\n",
    "#!/usr/bin/env python3\n",
    "# AUTHOR: Sara Fraija\n",
    "# This script allows generating bash files to compute upper limits for each GRB. \n",
    "# You can change the GRB list, energy ranges, and EBL model.\n",
    "\n",
    "# import pandas as pd\n",
    "# import subprocess\n",
    "# import os\n",
    "# # ------------------------------------------------------------------------\n",
    "# # PATHS & FILENAMES\n",
    "# # ------------------------------------------------------------------------\n",
    "# energy_ranges = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/Energy_ranges.csv'\n",
    "# GRBINFO_folder = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/'\n",
    "# OUTPUT_folder = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/files/2.5/PSF_0.25/'\n",
    "# os.makedirs(OUTPUT_folder, exist_ok=True)\n",
    "# PATH_SH = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/codes/'\n",
    "# RECALCULATED = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/corrected/'\n",
    "\n",
    "# # Leer Energy_ranges.csv con nombres de columnas correctos\n",
    "# Energy_ranges = pd.read_csv(energy_ranges, names=['Name', 'Emin', 'Emax'])\n",
    "# Energy_ranges = Energy_ranges.set_index('Name')\n",
    "# Energy_ranges.sort_values(by='Name')\n",
    "# # ------------------------------------------------------------------------\n",
    "# # Function to generate bash script\n",
    "# # ------------------------------------------------------------------------\n",
    "# def script(GRBINFO, transit, PATH_SH, OUTPUT_folder, RECALCULATED, EBL, PSF):\n",
    "#     OUTPUT_FILE = f\"{OUTPUT_folder}UpperLimit_{transit}_{EBL}.csv\"\n",
    "\n",
    "#     # Leer archivo CSV con GRB information\n",
    "#     Data = pd.read_csv(GRBINFO)\n",
    "#     Data.sort_values('Name')\n",
    "#     # Verificar si la columna \"Name\" existe en el CSV\n",
    "#     if \"Name\" not in Data.columns:\n",
    "#         print(f\"Error: La columna 'Name' no está en {GRBINFO}. Verifica el formato del archivo.\")\n",
    "#         print(f\"Columnas disponibles: {Data.columns}\")\n",
    "#         return\n",
    "\n",
    "#     # Usar \"Name\" como índice\n",
    "#     Data = Data.set_index(\"Name\")\n",
    "\n",
    "#     # Asignar valores de Emin y Emax si existen en Energy_ranges\n",
    "#     Data['Emin'] = Data.index.map(Energy_ranges['Emin'])\n",
    "#     Data['Emax'] = Data.index.map(Energy_ranges['Emax'])\n",
    "#     # Verificar si hay valores NaN en Emin o Emax\n",
    "#     if Data[['Emin', 'Emax']].isna().any().any():\n",
    "#         print(\"Error: Algunos GRBs no tienen valores de Emin o Emax. Verifica Energy_ranges.csv.\")\n",
    "#         print(Data[['Emin', 'Emax']].isna().sum())\n",
    "#         return\n",
    "\n",
    "#     line = \"\"\n",
    "#     for grb in Data.index:  \n",
    "#         row = Data.loc[grb]\n",
    "#         RA = row['RA']\n",
    "#         Dec = row['DEC']\n",
    "#         z = row['z']\n",
    "        \n",
    "#         index = 2.07 if grb == 'GRB170817529' else 2.5\n",
    "\n",
    "#         Emin = row['Emin']\n",
    "#         Emax = row['Emax']\n",
    "#         line += f'PL=\"PowerLaw,1.0e-10,{index}\"\\n'\n",
    "#         line_1 = f\"ULs=$(zebra-flux-norm-fit -i $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB0C1_N1024.fits.gz $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB{{1..10}}C{{0..1}}_N1024.fits.gz -b B0C1 B{{1..10}}C{{0..1}} --extrapolate-low-z --dr $DR51 --ra {RA} --dec {Dec} -s $PL --ebl {EBL},{z} --pivot 1 --minE {Emin} --maxE {Emax} -V 3)\\n\"\n",
    "#         line_2 = f\"ULs=$(zebra-flux-norm-fit -i $dir/{grb}/transit_{transit}/{grb}_corrected_transit_{transit}_binB{{0..10}}C{{0..1}}_N1024.fits.gz -b B{{0..10}}C{{0..1}} --extrapolate-low-z --dr $DR51 --ra {RA} --dec {Dec} -s $PL --ebl {EBL},{z} --pivot 1 --minE {Emin} --maxE {Emax} -V 3)\\n\"\n",
    "#         line += line_1 if grb == 'GRB150110923' else line_2\n",
    "#         line += f'echo -e \"{grb},${{ULs}}\" >> $output_file\\n'\n",
    "        \n",
    "#     # Código base del script Bash\n",
    "#     code = f\"\"\"#! /usr/bin/env bash\n",
    "# #SBATCH --mem-per-cpu=4GB\n",
    "# #SBATCH -o {PATH_SH}/logs/UL.out\n",
    "# #SBATCH --mail-type=all\n",
    "# #SBATCH --mail-user=smfraijac@astro.unam.mx\n",
    "# #SBATCH -J UL\n",
    "# # Author: Sara Fraija\n",
    "# source /data/disk01/home/smfraijac/.bashrc\n",
    "# hawc_aerie\n",
    "# output_file={OUTPUT_FILE}\n",
    "# DR51=/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/config/pass5.f_DR/zebra-100pct-FHit.root\n",
    "# dir={RECALCULATED}\\n\n",
    "# output_file={OUTPUT_FILE}\\n\n",
    "# rm -f output_file\n",
    "# \"\"\"\n",
    "#     # Guardar el script Bash\n",
    "#     file_path = f\"{PATH_SH}UL{transit}_{EBL}_{PSF}.sh\"\n",
    "#     if os.path.exists(file_path):\n",
    "#         os.remove(file_path)\n",
    "#     with open(file_path, 'w') as bash_file:\n",
    "#         bash_file.write(code + line)\n",
    "#     print(f\"Script generado: {file_path}\")\n",
    "# # ------------------------------------------------------------------------\n",
    "# # Running script\n",
    "# # ------------------------------------------------------------------------\n",
    "# EBL_list = ['Franceschini08', 'Gilmore12Fiducial']\n",
    "\n",
    "# # for EBL in EBL_list:\n",
    "# #     File_1st_transit = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/Coordinates_with_Max_Sig_1_00.25.csv'\n",
    "# #     File_2nd_transit = '/lustre/hawcz01/scratch/userspace/jorgeamontes/GRB_KN/data/ULs/config/Coordinates_with_Max_Sig_2_00.25.csv'\n",
    "# #     script(File_1st_transit, transit=1, PATH_SH=PATH_SH, OUTPUT_folder=OUTPUT_folder, RECALCULATED=RECALCULATED, EBL=EBL, PSF=0.25)\n",
    "# #     script(File_2nd_transit, transit=2, PATH_SH=PATH_SH, OUTPUT_folder=OUTPUT_folder, RECALCULATED=RECALCULATED, EBL=EBL, PSF=0.25)\n",
    "# #     p1 = subprocess.Popen(['bash', f\"{PATH_SH}UL1_{EBL}_0.25.sh\"])\n",
    "# #     p2 = subprocess.Popen(['bash', f\"{PATH_SH}UL2_{EBL}_0.25.sh\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
