{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected 399.5773058293334 1.0448014511284677e-18 8.752347230349724\n",
      "original 191.4417006230236 0.26576551061413567 0.6256705994403441\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, chi2\n",
    "\n",
    "# Fisher's method combines p-values, so we need to convert significances (z-scores) to p-values\n",
    "def z_to_p(z):\n",
    "    return 2 * (1 - norm.cdf(abs(z)))\n",
    "\n",
    "# Fisher's method to combine p-values\n",
    "def fishers_method(p_values):\n",
    "    chi_stat = -2 * np.sum(np.log(p_values))\n",
    "    dof = 2 * len(p_values)\n",
    "    combined_p = chi2.sf(chi_stat, dof)\n",
    "    return chi_stat, combined_p\n",
    "\n",
    "# Original and corrected z-scores\n",
    "z_corrected = [-3.3187620143735597, 0.26001531179730614, 2.075586664428067, -4.836001257130424, -5.0058209698922065, -4.124807725419037, -6.708145430556573, -0.36453333603403965, 1.0099999999999996, 0.4100000000000001, 1.0800000000000003, 0.8899999999999998, 2.039999999999999, 0.0, 0.21000000000000002, 0.0, 0.8000000000000002, 0.0, 0.9700000000000002, 0.0, 0.0, 0.0, 2.7200000000000046, 1.6699999999999997, 1.0599999999999998, 0.5100000000000001, 0.5400000000000001, 0.0, 0.0, 2.549999999999998, 1.5600000000000003, 2.8700000000000054, 0.0, 0.0, 0.0, 0.0, 0.6100000000000002, 0.53, 0.48, 0.0, 0.0, 0.0, 0.24999999999999997, -2.5933070558261178, -0.8292210803671793, 1.4830717993535725, -5.302971520631429, -5.19865894117264, -0.6987210437981668, 1.776667592584381, -2.9760254098401253, -1.7192364133998934, -1.5341205443525463, 1.8000000000000003, 2.0100000000000007, 0.5400000000000001, 1.7899999999999998, 1.0200000000000002, 1.7300000000000006, 0.2999999999999998, 0.0, 0.26000000000000006, 0.19000000000000014, 0.009999999999999985, 1.0099999999999996, 0.0, 0.8300000000000002, 0.059999999999999984, 1.2200000000000002, 0.21999999999999992, 2.8999999999999986, 0.7400000000000003, 0.7200000000000001, 0.0, 0.27999999999999986, 0.0, 0.0, 2.200000000000001, 0.0, 0.0, 1.209999999999999, 0.0, 0.66, 1.2599999999999998, 2.1100000000000003, 1.5100000000000002, 1.7700000000000005, 0.0, 0.0, 0.98]\n",
    "z_original = [0.0, 1.7, 2.22, 0.27, 0.0, 0.57, 0.0, 0.75, 1.01, 0.41, 1.08, 0.89, 2.04, 0.0, 0.21, 0.0, 0.8, 0.0, 0.97, 0.0, 0.0, 0.0, 2.72, 1.67, 1.06, 0.51, 0.54, 0.0, 0.0, 2.55, 1.56, 2.87, 0.0, 0.0, 0.0, 0.0, 0.61, 0.53, 0.48, 0.0, 0.0, 0.0, 0.25, 0.3, 1.11, 1.66, 0.24, 0.17, 1.53, 3.04, 0.98, 0.92, 0.0, 1.8, 2.01, 0.54, 1.79, 1.02, 1.73, 0.3, 0.0, 0.26, 0.19, 0.01, 1.01, 0.0, 0.83, 0.06, 1.22, 0.22, 2.9, 0.74, 0.72, 0.0, 0.28, 0.0, 0.0, 2.2, 0.0, 0.0, 1.21, 0.0, 0.66, 1.26, 2.11, 1.51, 1.77, 0.0, 0.0, 0.98]\n",
    "\n",
    "# i=z_original.index(3.45)\n",
    "# z_original.remove(z_original[i])\n",
    "# z_corrected.remove(z_corrected[i])\n",
    "# Convert to p-values\n",
    "p_corrected = [z_to_p(z) for z in z_corrected]\n",
    "p_original = [z_to_p(z) for z in z_original]\n",
    "\n",
    "# Apply Fisher's method\n",
    "chi_corr, p_comb_corr = fishers_method(p_corrected)\n",
    "chi_orig, p_comb_orig = fishers_method(p_original)\n",
    "\n",
    "# Create table\n",
    "results_df = pd.DataFrame({\n",
    "    \"Set\": [\"Corrected\", \"Original\"],\n",
    "    \"Chi^2\": [chi_corr, chi_orig],\n",
    "    \"p-value\": [p_comb_corr, p_comb_orig]\n",
    "})\n",
    "\n",
    "\n",
    "print('corrected',chi_corr, p_comb_corr,norm.isf(p_comb_corr))\n",
    "print('original',chi_orig, p_comb_orig ,norm.isf(p_comb_orig))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826894921370859"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-z_to_p(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance_to_pvalue(z):\n",
    "    return norm.sf(z)\n",
    "\n",
    "def process_file(filepath, ref_psf):\n",
    "    df = pd.read_csv()\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        name = row['Name']\n",
    "        transit = row['transit']\n",
    "        sig = row['Significance']\n",
    "        psf = row['PSF']\n",
    "        p_val = significance_to_pvalue(sig)\n",
    "        pdf_val = norm.pdf(sig)\n",
    "        trials_factor = (psf**2) / (ref_psf**2)\n",
    "        p_corr = 1- np.power(p_val,trials_factor)\n",
    "        sig_corr = norm.isf(p_corr) \n",
    "        results.append((name, transit, sig, sig_corr, p_val, 1-p_corr, pdf_val))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_original.index(3.45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libraries'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibraries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataframe_generator\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mastropy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fits\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libraries'"
     ]
    }
   ],
   "source": [
    "# libraries/ul_plot.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from libraries import dataframe_generator\n",
    "from scipy.stats import norm\n",
    "from astropy.io import fits\n",
    "\n",
    "def non_to_int2(E1, E2, flux, alpha, pivot):\n",
    "    \"\"\"Convierte un flujo a un valor integrado según el índice espectral.\"\"\"\n",
    "    A = flux / (pivot ** (-alpha))\n",
    "    if alpha > 2:\n",
    "        F1 = (E2 ** (2 - alpha)) / (2 - alpha)\n",
    "        F2 = (E1 ** (2 - alpha)) / (2 - alpha)\n",
    "        return 1.6 * A * (F1 - F2)\n",
    "    elif alpha == 2:\n",
    "        F3 = np.log(E2)\n",
    "        F4 = np.log(E1)\n",
    "        return A * (F3 - F4)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def expected_value(values, weights):\n",
    "    \"\"\"Calcula el valor esperado dada una lista de valores y sus pesos.\"\"\"\n",
    "    values = np.asarray(values)\n",
    "    weights = np.asarray(weights)\n",
    "    return (values * weights).sum() / weights.sum()\n",
    "\n",
    "def generate_upper_limits_plots(config):\n",
    "    \"\"\"\n",
    "    Genera DataFrames, procesa los datos y produce gráficos con los límites superiores\n",
    "    obtenidos por los métodos Franceschini y Gilmore.\n",
    "    \"\"\"\n",
    "    # Usar 'BASE_DIR' si existe, de lo contrario usar 'PATH_BASE'\n",
    "    BASE_DIR = config.get('BASE_DIR', config.get('PATH_BASE'))\n",
    "    bin_size = config['bin_size']\n",
    "    spectral_index = config['spectral_index']\n",
    "    GRB_KN_DIR = config['GRB_KN_DIR']\n",
    "    GITLAB_DIR = config['GITLAB_DIR']\n",
    "    \n",
    "    # Construir rutas a partir de directorios base\n",
    "    csvfile = config['GRBsINFO']\n",
    "    path_zenith = os.path.join(GITLAB_DIR, 'UpperLimits/CSV_FILES_trials/GRB_COORDINATES/zenith.txt')\n",
    "    upper_limit_dir = os.path.join(GRB_KN_DIR, f'data/ULs/files/PSF_{bin_size}', f'alfa={spectral_index}')\n",
    "    \n",
    "    Franceschini_1stT = os.path.join(upper_limit_dir, 'UpperLimit_1_Franceschini08.csv')\n",
    "    Franceschini_2ndT = os.path.join(upper_limit_dir, 'UpperLimit_2_Franceschini08.csv')\n",
    "    Gilmore_1stT = os.path.join(upper_limit_dir, 'UpperLimit_1_Gilmore12Fiducial.csv')\n",
    "    Gilmore_2ndT = os.path.join(upper_limit_dir, 'UpperLimit_2_Gilmore12Fiducial.csv')\n",
    "    print(Franceschini_1stT, 'eta')\n",
    "    energy_file = config['energy_ranges']\n",
    "    \n",
    "    plots_dir = config.get('plots_dir', '../plots')\n",
    "    plot_first_path = os.path.join(plots_dir, 'plot_first_transit_hd.png')\n",
    "    plot_second_path = os.path.join(plots_dir, 'plot_second_transit_hd.png')\n",
    "    \n",
    "    # Generar DataFrames usando el módulo dataframe_generator\n",
    "    df_franceschini = dataframe_generator.DATAFRAME_generator(Franceschini_2ndT, Franceschini_1stT, csvfile, path_zenith)\n",
    "    df_gilmore = dataframe_generator.DATAFRAME_generator(Gilmore_2ndT, Gilmore_1stT, csvfile, path_zenith)\n",
    "    df_franceschini.to_csv('data.csv')\n",
    "    df_gilmore.to_csv('data2.csv')\n",
    "    # Limpieza de nombres, ordenación y eliminación de duplicados\n",
    "    df_franceschini['Name'] = df_franceschini[\"Name\"].str.replace(',', '', regex=True)\n",
    "    df_gilmore['Name'] = df_gilmore[\"Name\"].str.replace(',', '', regex=True)\n",
    "    df_franceschini=df_franceschini.drop_duplicates()\n",
    "    df_franceschini.sort_values(by='Name', inplace=True)\n",
    "    df_gilmore.sort_values(by='Name', inplace=True)\n",
    "    df_gilmore=df_gilmore.drop_duplicates()\n",
    "    \n",
    "    Names = df_franceschini[\"Name\"]\n",
    "    DEC = df_franceschini['Dec'].copy()\n",
    "    # if len(DEC) > 13:\n",
    "    #     DEC.iloc[13] = -23  # Ajuste manual si es necesario\n",
    "    \n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, 20))[:14]\n",
    "    color_hex = [matplotlib.colors.rgb2hex(color) for color in colors]\n",
    "    \n",
    "# This section of the code is performing the following tasks:\n",
    "    # Cargar archivo de energía y convertir a numérico\n",
    "    Energy = pd.read_csv(energy_file, header=None, names=['Name', 'E1', 'E2'])\n",
    "    Energy.sort_values(by='Name', inplace=True)\n",
    "    Energy[['E1', 'E2']] = Energy[['E1', 'E2']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Asegurar que los límites superiores también son numéricos\n",
    "    df_franceschini['upperBound'] = pd.to_numeric(df_franceschini['upperBound'], errors='coerce')\n",
    "    df_franceschini['upperBound_2ndT'] = pd.to_numeric(df_franceschini['upperBound_2ndT'], errors='coerce')\n",
    "    df_gilmore['upperBound'] = pd.to_numeric(df_gilmore['upperBound'], errors='coerce')\n",
    "    df_gilmore['upperBound_2ndT'] = pd.to_numeric(df_gilmore['upperBound_2ndT'], errors='coerce')\n",
    "\n",
    "    # Calcular ULs integradas\n",
    "    UL_Franceschini_1 = non_to_int2(Energy['E1'], Energy['E2'], df_franceschini['upperBound'], spectral_index, 1)\n",
    "    UL_Franceschini_2 = non_to_int2(Energy['E1'], Energy['E2'], df_franceschini['upperBound_2ndT'], spectral_index, 1)\n",
    "    UL_Gilmore_1 = non_to_int2(Energy['E1'], Energy['E2'], df_gilmore['upperBound'], spectral_index, 1)\n",
    "    UL_Gilmore_2 = non_to_int2(Energy['E1'], Energy['E2'], df_gilmore['upperBound_2ndT'], spectral_index, 1)\n",
    "\n",
    "    # Guardar por si acaso\n",
    "    DATA = pd.DataFrame({'F': UL_Franceschini_1, 'G': UL_Gilmore_1})\n",
    "    DATA.to_csv('UL.csv')\n",
    "\n",
    "    def plot_ul(names, dec, ul_franceschini, ul_gilmore, color_hex,\n",
    "                xlabel=r'Declinación [grados]',\n",
    "                ylabel=r'$\\Phi$ [ergs cm$^{-2}$ s$^{-1}$]',\n",
    "                xlim=(-25, 65), ylim=(1e-13, 1e-8),\n",
    "                save_path=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        for grb, ul_g, d, col in zip(names, ul_gilmore, dec, color_hex):\n",
    "            ax.errorbar(x=d, y=ul_g, yerr=ul_g / 10, uplims=True, color=col, label=grb)\n",
    "        ax.set_yscale('log')\n",
    "        for grb, ul_f, ul_g, d, col in zip(names, ul_franceschini, ul_gilmore, dec, color_hex):\n",
    "            ax.fill_between([d - 1, d + 1], [ul_f, ul_f], [ul_g, ul_g], color=col, alpha=0.3)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        # ax.legend(bbox_to_anchor=(1.05, 1))\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    plot_ul(Names, DEC, UL_Franceschini_1, UL_Gilmore_1, color_hex, save_path=plot_first_path)\n",
    "    plot_ul(Names, DEC, UL_Franceschini_2, UL_Gilmore_2, color_hex, save_path=plot_second_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
